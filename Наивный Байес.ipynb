{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81303587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# посмотрим на данные - в этот раз датасет доступен напрямую из sklearn.\n",
    "# выведем все доступные категории.\n",
    "# параметр subset отвечает за разделенение данных (train - тренировочная выборка, test - тестовая).\n",
    "\n",
    "# параметр remove говорит о том, какие части данных нужно удалить, чтобы не допустить переобучения.\n",
    "# headers - заголовки новостных групп\n",
    "# quotes - удаление строк, похожих на цитаты из других источников\n",
    "# footers - удаление блоков из конца текста, похожих на подписи\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import numpy as np\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
    "newsgroups_train.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b0ba81",
   "metadata": {},
   "source": [
    "Мы будем использовать только 4 класса текстов: alt.atheism, sci.space, talk.religion.misc, comp.graphics. Используя параметр categories в функции fetch_20newsgroups, задайте список нужных нам категорий и разбейте данные на тренировочную и тестовые части (параметр subset).\n",
    "\n",
    "Учтите, что сами данные (целевые и нецелевые признаки) лежат в атрибутах data и target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14dfac2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['alt.atheism','sci.space','talk.religion.misc','comp.graphics']\n",
    "\n",
    "newgroups_train = fetch_20newsgroups(categories=categories,subset='train',remove=('headers','footers','quotes'))\n",
    "\n",
    "newgroups_test = fetch_20newsgroups(categories=categories,subset='test',remove=('headers','footers','quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25a4a8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = newgroups_train.data\n",
    "y_train = newgroups_train.target\n",
    "X_test = newgroups_test.data\n",
    "y_test = newgroups_test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87aef583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'str'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train))\n",
    "print(type(X_train[0]))\n",
    "print(type(y_train))\n",
    "print(type(y_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cdecfc",
   "metadata": {},
   "source": [
    "Выведите на экран по 1 тексту из каждой категории."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "447c2c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have a request for those who would like to see Charley Wingate\n",
      "respond to the \"Charley Challenges\" (and judging from my e-mail, there\n",
      "appear to be quite a few of you.)  \n",
      "\n",
      "It is clear that Mr. Wingate intends to continue to post tangential or\n",
      "unrelated articles while ingoring the Challenges themselves.  Between\n",
      "the last two re-postings of the Challenges, I noted perhaps a dozen or\n",
      "more posts by Mr. Wingate, none of which answered a single Challenge.  \n",
      "\n",
      "It seems unmistakable to me that Mr. Wingate hopes that the questions\n",
      "will just go away, and he is doing his level best to change the\n",
      "subject.  Given that this seems a rather common net.theist tactic, I\n",
      "would like to suggest that we impress upon him our desire for answers,\n",
      "in the following manner:\n",
      "\n",
      "1. Ignore any future articles by Mr. Wingate that do not address the\n",
      "Challenges, until he answers them or explictly announces that he\n",
      "refuses to do so.\n",
      "\n",
      "--or--\n",
      "\n",
      "2. If you must respond to one of his articles, include within it\n",
      "something similar to the following:\n",
      "\n",
      "    \"Please answer the questions posed to you in the Charley Challenges.\"\n",
      "\n",
      "Really, I'm not looking to humiliate anyone here, I just want some\n",
      "honest answers.  You wouldn't think that honesty would be too much to\n",
      "ask from a devout Christian, would you?  \n",
      "\n",
      "Nevermind, that was a rhetorical question.\n",
      "Hi,\n",
      "\n",
      "I've noticed that if you only save a model (with all your mapping planes\n",
      "positioned carefully) to a .3DS file that when you reload it after restarting\n",
      "3DS, they are given a default position and orientation.  But if you save\n",
      "to a .PRJ file their positions/orientation are preserved.  Does anyone\n",
      "know why this information is not stored in the .3DS file?  Nothing is\n",
      "explicitly said in the manual about saving texture rules in the .PRJ file. \n",
      "I'd like to be able to read the texture rule information, does anyone have \n",
      "the format for the .PRJ file?\n",
      "\n",
      "Is the .CEL file format available from somewhere?\n",
      "\n",
      "Rych\n",
      "\n",
      " >In article <1993Apr19.020359.26996@sq.sq.com>, msb@sq.sq.com (Mark Brader) \n",
      "\n",
      "MB>                                                             So the\n",
      "MB> 1970 figure seems unlikely to actually be anything but a perijove.\n",
      "\n",
      "JG>Sorry, _perijoves_...I'm not used to talking this language.\n",
      "\n",
      "Couldn't we just say periapsis or apoapsis?\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "Seems to be, barring evidence to the contrary, that Koresh was simply\n",
      "another deranged fanatic who thought it neccessary to take a whole bunch of\n",
      "folks with him, children and all, to satisfy his delusional mania. Jim\n",
      "Jones, circa 1993.\n",
      "\n",
      "\n",
      "Nope - fruitcakes like Koresh have been demonstrating such evil corruption\n",
      "for centuries.\n"
     ]
    }
   ],
   "source": [
    "for i in range(np.unique(y_train).shape[0]):\n",
    "    print(np.array(X_train)[y_train==i][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73458303",
   "metadata": {},
   "source": [
    "проведем небольшой эксперимент по отбору признаков: датасет изкоробочный, специально для обучения машинному обучению (sic), НО...\n",
    "... проверим данные на наличие пробелов и пустых строк"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7d841a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n",
      "4\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(X_train.count(''))\n",
    "print(X_train.count(' '))\n",
    "print(X_train.count('  '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07432642",
   "metadata": {},
   "source": [
    "Как мы видим, среди признаков внезапно оказались пустые строки, и этим пустым строкам присвоен класс! Очевидно, что такое недопустимо, поэтому датасет необходимо немного вычистить.\n",
    "\n",
    "Заметьте, что мы делаем проверку на строку с 1м, 2мя, 3мя пробелами, но не с 5 пробелами и больше. Чтобы эффективно найти строки с некоторым неизвестным числом пробелов, чтоит воспользоваться регулярным выражением ^\\\\s*$ - данная регулярка срабатывает на строках, состоящих целиком из пробелов (\\s - это пробельный символ, квантификатор * указывает, что число повторений такого символа больше одного, символ ^ указывает на начало строки, а знак доллара- на конец строки).\n",
    "\n",
    "Для нахождения возьмем функцию match из библиотеки re регулярных выражений в питоне.\n",
    "Доки по функции match. Обратите внимание, что она возвратит None, если паттерн не совпал с заданной строкой, или возвратит некий match object, если будет совпадение.\n",
    "\n",
    "Задача: в тестовой и тренировочной выборках найти индексы пробельных строк. Зная индексы (это должен быть массив индексов), можно удалить такие элементы из тренировочной и тестовой выборок. Для удаления можете использовать логические маски, или np.delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7946d75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2034\n",
      "1353\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7a0871f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "pattern = re.compile('^\\s*$')\n",
    "\n",
    "######\n",
    "### ВАШ КОД\n",
    "\n",
    "######\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "X_train_fix = np.array(X_train)[np.array([re.match(pattern,i) for i in X_train])==None]\n",
    "\n",
    "y_train = y_train[np.array([re.match(pattern,i) for i in X_train])==None]\n",
    "\n",
    "X_test_fix = np.array(X_test)[np.array([re.match(pattern,i) for i in X_test])==None]\n",
    "\n",
    "y_test = y_test[np.array([re.match(pattern,i) for i in X_test])==None]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b30758b",
   "metadata": {},
   "source": [
    "Выведем число элементов после очистки, должно получиться 1977 и 1318 элементов в тренировочной и тестовой выборках:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3672ed41",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(y_train) == 1977\n",
    "assert len(X_train_fix) == 1977\n",
    "assert len(y_test) == 1318\n",
    "assert len(X_test_fix) == 1318"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec7a7d8",
   "metadata": {},
   "source": [
    "Посмотрим на то, что из себя представляют целевые признаки. Это целое число, обозначающее индекс категории.\n",
    "Преобразуем этот индекс в имя категории. Для этого воспользуемся генератором списков и методом target_names, который по индексу вернет нам название категории."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37577f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array([newgroups_train.target_names[i] for i in y_train])\n",
    "y_test = np.array([newgroups_test.target_names[i] for i in y_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "17455223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['alt.atheism', 'comp.graphics', 'sci.space', 'talk.religion.misc'],\n",
       "      dtype='<U18')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e76dfe6",
   "metadata": {},
   "source": [
    "Для работы со счетчиками мы возьмем реализацию из библиотеки sklearn.\n",
    "\n",
    "по ссылке тут можно почитать про сами счетчики (мешок слов и TF-IDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea318dc6",
   "metadata": {},
   "source": [
    "Мешок слов\n",
    "Документация\n",
    "\n",
    "Можно начать с очень простой идеи. Давайте разобъем все предложения на слова. Составим словарь всех слов, которые будут встречаться во всех наших текстах. И отметим, встречается ли это слово в нашем конкретном примере. Другими словами, пусть в таблице в строках будут предложения, в столбцах - слова, а в ячейках число, которое показывает сколько раз это слово встречалось в этом предложении. Получается, что каждому объекту выборки будет сопоставлен вектор.\n",
    "\n",
    "Векторизацию мы делаем сразу методом fit_transform - он эквивалентен последовательному вызову\n",
    "\n",
    "bow = count_vectorizer.fit(data).transform(data)\n",
    "Очевидно, что метод fit составляет словарь, а transform делает вектор из предложения, согласно имеющемуся словарю."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4bd3d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape= (3, 28)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "texts = [\n",
    "    \"I've been searching for the right words to thank you for this breather.\",\n",
    "    \"You have been wonderful and a blessing at all times\",\n",
    "    \"I promise i wont take your help for granted and will fulfil my promise.\"\n",
    "]\n",
    "bow = count_vectorizer.fit_transform(texts)\n",
    "print(\"Shape=\", bow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "65cfd899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ve': 21,\n",
       " 'been': 3,\n",
       " 'searching': 14,\n",
       " 'for': 6,\n",
       " 'the': 17,\n",
       " 'right': 13,\n",
       " 'words': 25,\n",
       " 'to': 20,\n",
       " 'thank': 16,\n",
       " 'you': 26,\n",
       " 'this': 18,\n",
       " 'breather': 5,\n",
       " 'have': 9,\n",
       " 'wonderful': 23,\n",
       " 'and': 1,\n",
       " 'blessing': 4,\n",
       " 'at': 2,\n",
       " 'all': 0,\n",
       " 'times': 19,\n",
       " 'promise': 12,\n",
       " 'wont': 24,\n",
       " 'take': 15,\n",
       " 'your': 27,\n",
       " 'help': 10,\n",
       " 'granted': 8,\n",
       " 'will': 22,\n",
       " 'fulfil': 7,\n",
       " 'my': 11}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# посмотрим на словарь всех слов (метод vocabulary_)\n",
    "# число - это индекс слова в строке матрицы\n",
    "\n",
    "count_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88150234",
   "metadata": {},
   "source": [
    "Теперь составим ту самую матрицу, где в столбцах слова, а в строках тексты.\n",
    "\n",
    "Как мы видим, в первом и втором предложениях есть слово \"been\", а в третьем его нет (так как у \"been\" индекс равен 3).\n",
    "Так как векторайзер возвращает разряженную матрицу, то воспользуемся методом .toarray(), чтобы превратить ее в numpy-массив."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "22ce5ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 0, 1, 2, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "        0, 0, 0, 1, 1, 0],\n",
       "       [1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 1, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 1, 0, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d4e5df",
   "metadata": {},
   "source": [
    "При векторизации можно удалить \"стоп-слова\" - они не несут какого-то смысла, но нужны для грамматики (параметр stop_words). Как мы видим, словарь стал заметно меньше, соответсвенно и вектор тоже стал короче."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "caf08679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape= (3, 14)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ve': 10,\n",
       " 'searching': 7,\n",
       " 'right': 6,\n",
       " 'words': 13,\n",
       " 'thank': 8,\n",
       " 'breather': 1,\n",
       " 'wonderful': 11,\n",
       " 'blessing': 0,\n",
       " 'times': 9,\n",
       " 'promise': 5,\n",
       " 'wont': 12,\n",
       " 'help': 4,\n",
       " 'granted': 3,\n",
       " 'fulfil': 2}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "bow = count_vectorizer.fit_transform(texts)\n",
    "print(\"Shape=\", bow.shape)\n",
    "count_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73023461",
   "metadata": {},
   "source": [
    "Мешок слов не учитывает \"веса\" слов, он просто смотрит их вхождение в документ. Вероятно, было бы полезно взвесить каким-то образом каждое слово в документе. Действительно, если слово встречается во всех документах, то, наверное, его вес небольшой. А если редкое слово встречается в некоторых документах, то скорее всего оно какое-то узко тематическое.\n",
    "\n",
    "Один из способов взвесить слова - это использовать меру tf-idf, где:\n",
    "\n",
    "TF - term frequency - частота слова для каждой статьи\n",
    "\n",
    "\n",
    "IDF - inverse document frequency* — обратная частота документа - уменьшает вес часто встречаемых слов\n",
    "\n",
    "\n",
    "TF-IDF = TF * IDF\n",
    "\n",
    "Синтаксис такой же, как и у мешка слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39084ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape= (3, 14)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "texts = [\n",
    "    \"I've been searching for the right words to thank you for this breather.\",\n",
    "    \"You have been wonderful and a blessing at all times\",\n",
    "    \"I promise i wont take your help for granted and will fulfil my promise.\"\n",
    "]\n",
    "bow = tfidf_vectorizer.fit_transform(texts)\n",
    "print(\"Shape=\", bow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fe72bb5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ve': 10,\n",
       " 'searching': 7,\n",
       " 'right': 6,\n",
       " 'words': 13,\n",
       " 'thank': 8,\n",
       " 'breather': 1,\n",
       " 'wonderful': 11,\n",
       " 'blessing': 0,\n",
       " 'times': 9,\n",
       " 'promise': 5,\n",
       " 'wont': 12,\n",
       " 'help': 4,\n",
       " 'granted': 3,\n",
       " 'fulfil': 2}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6b37c291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.40824829, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.40824829, 0.40824829, 0.40824829, 0.        ,\n",
       "        0.40824829, 0.        , 0.        , 0.40824829],\n",
       "       [0.57735027, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.57735027,\n",
       "        0.        , 0.57735027, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.35355339, 0.35355339, 0.35355339,\n",
       "        0.70710678, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.35355339, 0.        ]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7ca86a",
   "metadata": {},
   "source": [
    "Обратясь к примерам выше и к документации по ссылкам, создайте векторайзеры для подготовленных в предыдущем параграфе данных. Используйте английские стоп-слова.\n",
    "\n",
    "Так как у нас есть две части (тренировочная и тестовая выборки), то векторайзер нужно обучить на словах из обоих выборок (подумайте, почему). Так как у нас питон, а наши выборки это массивы строк, то объеденить их очень просто - просто сложить. После того, как вы обучили векторайзер на всех словах, проведите трансформации отдельно для тестовой, и отдельно для тренировочных частей.\n",
    "\n",
    "Векторизованные части назовите xcv_test/train для count_vectorizer, и xTfidf_test/train для TF-IDF - это нужно для корректной работы тестов и примеров ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b629980b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_cv = CountVectorizer(stop_words='english')\n",
    "vect_cv.fit(np.array(list(X_train_fix) + list(X_test_fix)))\n",
    "\n",
    "Xcv_train = vect_cv.transform(X_train_fix)\n",
    "\n",
    "Xcv_test = vect_cv.transform(X_test_fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adc1d389",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_tf = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "vect_tf.fit(np.array(list(X_train_fix) + list(X_test_fix)))\n",
    "\n",
    "XTfidf_train = vect_tf.transform(X_train_fix)\n",
    "\n",
    "XTfidf_test = vect_tf.transform(X_test_fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ae729d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count vectorizer\n",
    "assert Xcv_train.shape == (1977, 33529)\n",
    "assert Xcv_test.shape == (1318, 33529)\n",
    "\n",
    "#tf-idf\n",
    "assert XTfidf_train.shape == (1977, 33529)\n",
    "assert XTfidf_test.shape == (1318, 33529)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574af41f",
   "metadata": {},
   "source": [
    "Вспомните статью из блога, которая была в самом начале.\n",
    "\n",
    "Модель классификатора строится на основе обучающей выборки. По ней необходимо найти следующюю статистику:\n",
    "\n",
    " 1 Частоты классов в корпусе объектов (сколько объектов принадлежит каждому из классов) (classes_stats)\n",
    " 2 Cуммарное число слов в документах каждого класса (words_per_class, далее см. )\n",
    " 3 Частоты слов в пределах каждого класса (word_freqs_per_class, далее используется для расчета )\n",
    " 4 Размер словаря выборки (число признаков) - кол-во уникальных слов в выборке (num_features)\n",
    "По сути, это метод fit классификатора\n",
    "\n",
    "Сигнатура класса:\n",
    "\n",
    "class NaiveBayes:\n",
    "    def fit(self, x, y) -> None\n",
    "\n",
    "    def predict(self, x) -> List[Int]\n",
    "Для начала отдельно подсчитаем различные статистики, описанные в статье и в материале выше. Так как у нас уже готовы все данные, то считать будем по count_vectorizer'у (то есть xcv_ ...).\n",
    "\n",
    "Общее число документов в обучающей выборке (doc_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0edc4e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_num = Xcv_train.shape[0]\n",
    "# ПРОВЕРКА\n",
    "assert doc_num == 1977"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2daaf97d",
   "metadata": {},
   "source": [
    "Словарь, содержащий число объектов каждого класса (classes_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0123df35",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_stats = {i:np.sum(y_train == i) for i in np.unique(y_train)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac4db1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ПРОВЕРКА\n",
    "assert classes_stats['alt.atheism'] == 468\n",
    "assert classes_stats['comp.graphics'] == 571\n",
    "assert classes_stats['sci.space'] == 577\n",
    "assert classes_stats['talk.religion.misc'] == 361"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206480d1",
   "metadata": {},
   "source": [
    "Число уникальных признаков (слов) в тренировочной выборке (num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1eb9c2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = Xcv_train.shape[1]\n",
    "# ПРОВЕРКА\n",
    "assert num_features == 33529"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00b240d",
   "metadata": {},
   "source": [
    "Создадим словарь indexes, в котором ключом будет являться имя класса, а значением - список строк матрицы X, принадлежащих этому классу. Этот список пригодится нам дальше, так как будет играть роль маски. Для поиска класса каждой из строк используйте целевой вектор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4100b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = {i:[ind for ind,elem in enumerate(y_train==i) if elem] for i in np.unique(y_train)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f868f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ПРОВЕРКА\n",
    "# так как в словаре очень много элементов, то проверим случайные элементы из списка.\n",
    "# если вы все сделали правильно, то эти элементы совпадут.\n",
    "assert indexes['sci.space'][35] == 111\n",
    "assert indexes['comp.graphics'][42] == 159\n",
    "assert indexes['talk.religion.misc'][67] == 312\n",
    "assert indexes['alt.atheism'][89] == 372"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a84bd0",
   "metadata": {},
   "source": [
    "Используя найденные выше индексы, подсчитаем два важных параметра words_per_class и word_freqs_per_class.\n",
    "Обе этих переменных являются словарями, но первая из них отвечает за суммарное число слов, использованных в каждом классе, а вторая показывает, сколько раз конкретное слово встретилось в документах определенного класса. Соответственно, формат переменной words_per_class - {str: int}, формат word_freqs_per_class - {str: List}. Мы специально объеденили поиск двух разных статистик в одном блоке, чтобы избежать лишних циклов.\n",
    "\n",
    "Чтобы найти в X строки, относящиеся к тому или иному классу, воспользуйтесь поиском по маске indexes для нужного класса.\n",
    "\n",
    "Также помните, что X - это разряженная матрица, но из нее можно получить обычный список через метод toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8539e323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'alt.atheism': 8737,\n",
       "  'comp.graphics': 10592,\n",
       "  'sci.space': 13273,\n",
       "  'talk.religion.misc': 8860},\n",
       " {'alt.atheism': array([ 0, 17,  0, ...,  0,  0,  0], dtype=int64),\n",
       "  'comp.graphics': array([26, 12,  0, ...,  0,  0,  2], dtype=int64),\n",
       "  'sci.space': array([32, 92,  2, ...,  0,  0,  0], dtype=int64),\n",
       "  'talk.religion.misc': array([1, 9, 0, ..., 0, 0, 0], dtype=int64)})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_arr = Xcv_train.toarray()\n",
    "\n",
    "words_per_class = {}\n",
    "word_freqs_per_class = {}\n",
    "\n",
    "for cls in indexes.keys():\n",
    "    class_idxs = indexes[cls] # нашли индексы строк матрицы, относящихся к классу cls\n",
    "\n",
    "    subarray_rows = x_arr[class_idxs] # нашли подмассив, относящийся к  классу cls\n",
    "    subarray_sum = np.sum(subarray_rows, axis = 0) # провели суммирование по столбцам\n",
    "    word_freqs_per_class[cls] = subarray_sum\n",
    "\n",
    "    words_per_class[cls] = len(subarray_sum[subarray_sum != 0]) # узнали,\n",
    "        # сколько слов было использовано в рамках одного класса, \n",
    "        # то есть просто подсчитали число ненулевых элементов\n",
    "\n",
    "words_per_class, word_freqs_per_class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3effc4b3",
   "metadata": {},
   "source": [
    "Все вышенаписанные переменные образуют метод fit будущего классификатора. Теперь внесите этот код в метод fit, и не забудьте сделать найденные переменные полями экземпляра класса при помощи self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4bb102",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        self.doc_num = x.shape[0] # Общее число документов в обучающей выборке (doc_num)\n",
    "        \n",
    "        self.classes_stats = {i:np.sum(y == i) for i in np.unique(y)} #Словарь, содержащий число объектов \n",
    "        # каждого класса (classes_stats)\n",
    "        \n",
    "        self.num_features = x.shape[1] # Число уникальных признаков (слов) в тренировочной выборке (num_features)\n",
    "        \n",
    "        self.indexes = {i:[ind for ind,elem in enumerate(y==i) if elem] for i in np.unique(y)} \n",
    "        \n",
    "        self.x_arr = x.toarray()\n",
    "\n",
    "        self.words_per_class = {} #  суммарное число слов, использованных в каждом классе\n",
    "        self.word_freqs_per_class = {} # вторая показывает, сколько раз конкретное слово встретилось \n",
    "        # в документах определенного класса\n",
    "\n",
    "        for cls in indexes.keys():\n",
    "            class_idxs = self.indexes[cls] # нашли индексы строк матрицы, относящихся к классу cls\n",
    "\n",
    "            subarray_rows = x_arr[class_idxs] # нашли подмассив, относящийся к  классу cls\n",
    "            subarray_sum = np.sum(subarray_rows, axis = 0) # провели суммирование по столбцам\n",
    "            self.word_freqs_per_class[cls] = subarray_sum\n",
    "\n",
    "            self.words_per_class[cls] = len(subarray_sum[subarray_sum != 0]) # узнали,\n",
    "        # сколько слов было использовано в рамках одного класса, \n",
    "        # то есть просто подсчитали число ненулевых элементов\n",
    "\n",
    "        self.words_per_class, self.word_freqs_per_class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621df7c7",
   "metadata": {},
   "source": [
    "Теперь реализуем метод predict. Вспомните еще раз большую формулу из начала этого раздела. Если вы внимательно читали статью, то заметили, что в примере мы получили не чистые вероятности классов, а всего лишь числовые оценки. Далее эти оценки можно перевести в вероятности, но мы этого делать не будем.\n",
    "\n",
    "Тогда промежуточный выход классификатора обозначим так:\n",
    "\n",
    "pred_per_class = {<номер строки в тестовой выборке>: {<класс 1>: <оценка>, ... , <класс n>: <оценка>}}\n",
    "\n",
    "Таким образом итоговый класс к которому будет отнесена строка - просто класс с наибольшей оценкой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "207a3871",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import math\n",
    "\n",
    "def predict(x):\n",
    "    x = x.toarray()\n",
    "    pred_per_class = defaultdict(dict)\n",
    "    for i in range(x.shape[0]):\n",
    "        pred_per_class[i] = {j:math.log(classes_stats[j]/doc_num) + \n",
    "                    np.sum(np.log((word_freqs_per_class[j][np.nonzero(x[i,])]+1)/(num_features+words_per_class[j])))\n",
    "                   for j in np.unique(y_train)}\n",
    "    pred = []\n",
    "    for i in range(x.shape[0]):\n",
    "        pred.append(max(pred_per_class[i],key=pred_per_class[i].get))\n",
    "    \n",
    "    return np.array(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a2b6ca0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверим размерность предсказаний.\n",
    "assert len(predict(Xcv_test)) == len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7edcf9e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sci.space', 'comp.graphics', 'comp.graphics', ..., 'sci.space',\n",
       "       'comp.graphics', 'comp.graphics'], dtype='<U18')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(Xcv_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e79957",
   "metadata": {},
   "source": [
    "Теперь соберем весь классфикатор вместе, внеся функцию predict внутрь ранее написанного класса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0e937e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        self.y = y\n",
    "        self.doc_num = x.shape[0] # Общее число документов в обучающей выборке (doc_num)\n",
    "        \n",
    "        self.classes_stats = {i:np.sum(y == i) for i in np.unique(y)} #Словарь, содержащий число объектов \n",
    "        # каждого класса (classes_stats)\n",
    "        \n",
    "        self.num_features = x.shape[1] # Число уникальных признаков (слов) в тренировочной выборке (num_features)\n",
    "        \n",
    "        self.indexes = {i:[ind for ind,elem in enumerate(y==i) if elem] for i in np.unique(y)} \n",
    "        \n",
    "        self.x_arr = x.toarray()\n",
    "\n",
    "        self.words_per_class = {} #  суммарное число слов, использованных в каждом классе\n",
    "        self.word_freqs_per_class = {} # вторая показывает, сколько раз конкретное слово встретилось \n",
    "        # в документах определенного класса\n",
    "\n",
    "        for cls in indexes.keys():\n",
    "            class_idxs = self.indexes[cls] # нашли индексы строк матрицы, относящихся к классу cls\n",
    "\n",
    "            subarray_rows = x_arr[class_idxs] # нашли подмассив, относящийся к  классу cls\n",
    "            subarray_sum = np.sum(subarray_rows, axis = 0) # провели суммирование по столбцам\n",
    "            self.word_freqs_per_class[cls] = subarray_sum\n",
    "\n",
    "            self.words_per_class[cls] = len(subarray_sum[subarray_sum != 0]) # узнали,\n",
    "        # сколько слов было использовано в рамках одного класса, \n",
    "        # то есть просто подсчитали число ненулевых элементов\n",
    "    \n",
    "    def predict(self,x):\n",
    "        import math\n",
    "        x = x.toarray()\n",
    "        pred_per_class = defaultdict(dict)\n",
    "        for i in range(x.shape[0]):\n",
    "            pred_per_class[i] = {j:math.log(self.classes_stats[j]/self.doc_num) + \n",
    "                    np.sum(np.log((self.word_freqs_per_class[j][np.nonzero(x[i,])]+1)/(self.num_features+self.words_per_class[j])))\n",
    "                   for j in np.unique(self.y)}\n",
    "        pred = []\n",
    "        for i in range(x.shape[0]):\n",
    "            pred.append(max(pred_per_class[i],key=pred_per_class[i].get))\n",
    "    \n",
    "        return np.array(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9553b89",
   "metadata": {},
   "source": [
    "В sklearn за матрицу ошибок и метрики отвечают confusion_matrix и classification_report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e5b8207d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.62      0.74      0.67       311\n",
      "     comp.graphics       0.91      0.90      0.90       384\n",
      "         sci.space       0.77      0.90      0.83       378\n",
      "talk.religion.misc       0.72      0.37      0.49       245\n",
      "\n",
      "          accuracy                           0.76      1318\n",
      "         macro avg       0.76      0.73      0.72      1318\n",
      "      weighted avg       0.77      0.76      0.75      1318\n",
      "\n",
      "[[229   9  41  32]\n",
      " [  9 344  31   0]\n",
      " [ 16  17 342   3]\n",
      " [117   8  29  91]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "nb_cv = NaiveBayes()\n",
    "\n",
    "nb_cv.fit(Xcv_train, y_train)\n",
    "pred = nb_cv.predict(Xcv_test)\n",
    "        \n",
    "print(classification_report(y_test, pred))\n",
    "print(confusion_matrix(y_test, pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1c8354",
   "metadata": {},
   "source": [
    "Проверим классификатор на полученных ранее tf-idf векторах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "56f766fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.62      0.74      0.67       311\n",
      "     comp.graphics       0.91      0.90      0.90       384\n",
      "         sci.space       0.77      0.90      0.83       378\n",
      "talk.religion.misc       0.72      0.37      0.49       245\n",
      "\n",
      "          accuracy                           0.76      1318\n",
      "         macro avg       0.76      0.73      0.72      1318\n",
      "      weighted avg       0.77      0.76      0.75      1318\n",
      "\n",
      "[[229   9  41  32]\n",
      " [  9 344  31   0]\n",
      " [ 16  17 342   3]\n",
      " [117   8  29  91]]\n"
     ]
    }
   ],
   "source": [
    "nb_tf = NaiveBayes()\n",
    "\n",
    "nb_tf.fit(XTfidf_train, y_train)\n",
    "pred = nb_tf.predict(XTfidf_test)\n",
    "        \n",
    "print(classification_report(y_test, pred))\n",
    "print(confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d44c01",
   "metadata": {},
   "source": [
    "Сравним с версией из sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "03155813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.62      0.75      0.68       311\n",
      "     comp.graphics       0.91      0.91      0.91       384\n",
      "         sci.space       0.83      0.89      0.86       378\n",
      "talk.religion.misc       0.68      0.42      0.52       245\n",
      "\n",
      "          accuracy                           0.78      1318\n",
      "         macro avg       0.76      0.74      0.74      1318\n",
      "      weighted avg       0.78      0.78      0.77      1318\n",
      "\n",
      "[[232   9  28  42]\n",
      " [ 12 351  20   1]\n",
      " [ 20  18 335   5]\n",
      " [112   9  20 104]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB(alpha=4)\n",
    "clf.fit(Xcv_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(Xcv_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "bc747bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.60      0.64      0.62       311\n",
      "     comp.graphics       0.84      0.93      0.88       384\n",
      "         sci.space       0.63      0.92      0.75       378\n",
      "talk.religion.misc       0.85      0.04      0.09       245\n",
      "\n",
      "          accuracy                           0.69      1318\n",
      "         macro avg       0.73      0.63      0.58      1318\n",
      "      weighted avg       0.73      0.69      0.63      1318\n",
      "\n",
      "[[199  22  88   2]\n",
      " [  1 356  27   0]\n",
      " [  5  24 349   0]\n",
      " [126  20  88  11]]\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB(alpha=4)\n",
    "clf.fit(XTfidf_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(XTfidf_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c9cf3c",
   "metadata": {},
   "source": [
    "Как вы заметили, качество предсказаний неоднородно (какие-то классы определяются хорошо, какие-то не очень хорошо). В чем может быть причина этого?\n",
    "\n",
    "Самостоятельно попробуйте найти топ-10 наиболее часто встречающихся слов в каждой категории, посмотрите на эти слова и напишите свои идеи, почему же при классификации точность падает на той или иной категории."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f68d8d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.sort(np.sum(Xcv_train.toarray()[y_train=='sci.space'],0))[-1:-11:-1]\n",
    "count = np.sum(Xcv_train.toarray()[y_train=='sci.space'],0)\n",
    "\n",
    "indx = []\n",
    "\n",
    "for i in range(count.shape[0]):\n",
    "    if count[i] in ind:\n",
    "        indx.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ca5b40d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9480, 11183, 17495, 18144, 18499, 20809, 21918, 27466, 28096, 30302]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f81fec8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for k,i in vect_cv.vocabulary_.items():\n",
    "    if i in indx:\n",
    "        res.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "4d05c799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['like',\n",
       " 'just',\n",
       " 'data',\n",
       " 'earth',\n",
       " 'space',\n",
       " 'time',\n",
       " 'orbit',\n",
       " 'launch',\n",
       " 'nasa',\n",
       " 'shuttle']"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
